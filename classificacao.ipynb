{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from libs import preprocessa, modelos, vo_X, metricas\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "random_state=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se estiver rodando localmente \n",
    "caminhoDados=\"dados/\"\n",
    "\n",
    "#Esse json é gerado no notebook TrataSegmentosAnotam.ipynb\n",
    "df  = pd.read_json(caminhoDados+'dfAlvoAnota.json') \n",
    "vocabulario = df[\"textoTotal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrar as classes mais relevantes a partir de 0.5% de presença\n",
    "classesInteresse = [1,3,9,22,24,13,10,4,25]\n",
    "\n",
    "#União Alt e inc\n",
    "df =  df[df['idTipoAnotacao'].isin(classesInteresse)]\n",
    "df.loc[df['idTipoAnotacao'] == 3, 'idTipoAnotacao'] = 1\n",
    "\n",
    "#dfInteresse.groupby(['idTipoAnotacao','nomeTipoAnotacao']).idSegmento.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Atributos iniciais\n",
    "y = df['idTipoAnotacao']\n",
    "\n",
    "dadosOriginais = []\n",
    "\n",
    "vocabulario = df[\"textoIntegraLimpo\"]\n",
    "x = preprocessa.vetorizaTFIDF(vocabulario,df[\"textoIntegraLimpo\"].astype(str))\n",
    "dadosOriginais.append(vo_X.vo_X(x,y,\"Segmento\"))\n",
    "\n",
    "vocabulario = df[\"verbosTextoIntegra\"]\n",
    "x = preprocessa.vetorizaTFIDF(vocabulario,df[\"verbosTextoIntegra\"].astype(str))\n",
    "dadosOriginais.append(vo_X.vo_X(x,y,\"VerbosSegmento\"))\n",
    "\n",
    "vocabulario = df[\"textoTotal\"]\n",
    "x = preprocessa.vetorizaTFIDF(vocabulario,df[\"textoTotal\"].astype(str))\n",
    "dadosOriginais.append(vo_X.vo_X(x,y,\"Segmento+Ementa\"))\n",
    "\n",
    "vocabulario = df[\"verbos\"]\n",
    "x = preprocessa.vetorizaTFIDF(vocabulario,df[\"verbos\"].astype(str))\n",
    "dadosOriginais.append(vo_X.vo_X(x,y,\"TodosVerbos\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seleção Atributos\n",
    "dadosChi = []\n",
    "for dados in dadosOriginais:\n",
    "    xChi1 = preprocessa.seleciona(vocabulario,dados.x, y,0.1)\n",
    "    dadosChi.append(vo_X.vo_X(xChi1,y, dados.estrategia + \" Chi 0.1\"))\n",
    "    \n",
    "    xChi25 = preprocessa.seleciona(vocabulario,dados.x, y,0.25)\n",
    "    dadosChi.append(vo_X.vo_X(xChi25,y, dados.estrategia + \" Chi 0.25\"))\n",
    "    \n",
    "    xChi50 = preprocessa.seleciona(vocabulario,dados.x, y,0.5)\n",
    "    dadosChi.append(vo_X.vo_X(xChi50,y, dados.estrategia + \" Chi 0.5\"))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reamostragem Smote\n",
    "smote = SMOTE(random_state=random_state)\n",
    "dadosSmote = []\n",
    "for dados in dadosOriginais:     \n",
    "    xs, ys = smote.fit_sample(dados.x,y)\n",
    "    dadosSmote.append(vo_X.vo_X(xs, ys, dados.estrategia + \" Smote\"))\n",
    "    \n",
    "for dados in dadosChi:     \n",
    "    xs, ys = smote.fit_sample(dados.x,y)\n",
    "    dadosSmote.append(vo_X.vo_X(xs, ys, dados.estrategia + \" Smote\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reamostragem NearMiss\n",
    "sampler = NearMiss()\n",
    "dadosNearMiss = []\n",
    "\n",
    "for dados in dadosOriginais: \n",
    "    xn, yn = sampler.fit_resample(dados.x,y)\n",
    "    dadosNearMiss.append(vo_X.vo_X(xn, yn, dados.estrategia + \" NearMiss\"))\n",
    "\n",
    "for dados in dadosChi:\n",
    "    xn, yn = sampler.fit_resample(dados.x,y)\n",
    "    dadosNearMiss.append(vo_X.vo_X(xn, yn, dados.estrategia + \" NearMiss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listaDados = [*dadosOriginais, *dadosChi, *dadosSmote, *dadosNearMiss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoGeral = []\n",
    "for dados in listaDados:\n",
    "    classificadores = modelos.classificadores()\n",
    "    classificadores.LSVC = True\n",
    "    classificadores.MNB = True\n",
    "    resultadosClassificacao =  classificadores.classificar(dados.x,dados.y)\n",
    "    for res in resultadosClassificacao:\n",
    "        res.insert(1, dados.estrategia) \n",
    "    resultadoGeral.extend(resultadosClassificacao)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado  = pd.DataFrame(resultadoGeral)\n",
    "df_resultado.columns = ['Modelo','Estratégia',\n",
    "                        'Acurácia %','DP','Precisão',\n",
    "                        'DP', 'Revocação','DP', 'F1','DP' ]\n",
    "df_resultado.loc[df_resultado['Modelo']=='LinearSVC','Modelo']='SVM'\n",
    "df_resultado.loc[df_resultado['Modelo']=='MultinomialNB','Modelo']='Naive Bayes'\n",
    "df_resultado.sort_values(['F1'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado.to_csv(\"resultado.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_resultado.sort_values(['F1'], ascending = False).to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}